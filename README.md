ğŸ§  RAG-Based AI Chatbot (Claude + Vector Search)
A production-ready Retrieval-Augmented Generation (RAG) chatbot that allows users to ask questions about custom documents (PDFs) and receive accurate, context-aware answers powered by Claude.
The system embeds documents into a vector store, retrieves the most relevant context at query time, and uses an LLM to generate grounded responses.
âœ¨ Features
ğŸ“„ PDF document ingestion
ğŸ” Semantic search with vector embeddings
ğŸ§  Retrieval-Augmented Generation (RAG)
ğŸ¤– Claude API integration
ğŸ’¾ Persistent vector store
ğŸ—‚ï¸ Conversation memory
ğŸŒ Web-based chat interface
ğŸš€ Backend connected to live Render deployment
ğŸ—ï¸ Architecture
Text
Copy code
User Query
   â†“
Vector Store (Similarity Search)
   â†“
Relevant Context Chunks
   â†“
Claude LLM
   â†“
Final Answer
ğŸ› ï¸ Tech Stack
Backend
Python
Claude (Anthropic API)
Vector embeddings
RAG pipeline
Frontend
HTML
JavaScript
Infrastructure
Render (backend hosting)
ğŸ“ Project Structure
Text
Copy code
.
â”œâ”€â”€ main.py                # Application entry point
â”œâ”€â”€ config.py              # Configuration & environment variables
â”œâ”€â”€ index.html             # Chat UI
â”‚
â”œâ”€â”€ document_loader.py     # PDF loading and text chunking
â”œâ”€â”€ vector_store.py        # Embedding and similarity search
â”œâ”€â”€ rag_engine.py          # Core RAG logic
â”‚
â”œâ”€â”€ model.py               # LLM wrapper
â”œâ”€â”€ claude_client.py       # Claude API client
â”œâ”€â”€ memory.py              # Conversation memory
â”‚
â”œâ”€â”€ start_chatbot.sh       # Startup script
â”œâ”€â”€ My-CV.pdf              # Sample document
â””â”€â”€ README.md
ğŸš€ Getting Started
1. Prerequisites
Python 3.9+
Claude API key (Anthropic)
2. Clone the Repository
Bash
Copy code
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
3. Install Dependencies
Bash
Copy code
pip install -r requirements.txt
4. Environment Variables
Create a .env file:
Env
Copy code
CLAUDE_API_KEY=your_api_key_here
5. Run the Application
Bash
Copy code
python main.py
Then open index.html in your browser.
ğŸ§ª Example Use Cases
Resume / CV Q&A
Document-based chatbot
Internal knowledge assistant
Research and study assistant
Personal AI assistant with memory
ğŸ§  How It Works
Documents are loaded and split into chunks
Chunks are embedded and stored in a vector database
User queries are embedded
Most relevant chunks are retrieved
Claude generates an answer using retrieved context
This approach reduces hallucinations and improves factual accuracy.
ğŸ“Œ Roadmap
[ ] Streaming responses
[ ] Multiple document uploads
[ ] Vector store persistence (FAISS / Chroma)
[ ] Authentication
[ ] Improved UI
[ ] Docker support
ğŸ” Security Notes
API keys are stored in environment variables
Never commit .env files
Add rate limiting for public deployment
ğŸ“„ License
MIT License
â­ Project Highlights
This project demonstrates:
Real-world RAG implementation
LLM integration with Claude
Semantic search
Backend deployment
Modular, readable codebase
Ideal for portfolio, startup prototypes, or production foundations.
